import streamlit as st
from openai import OpenAI
import json
import re
import numpy as np
import msc_config as config
import msc_db as db

# ğŸ›‘ AI åˆå§‹åŒ–
try:
    client_ai = OpenAI(api_key=st.secrets["API_KEY"], base_url=st.secrets["BASE_URL"])
    TARGET_MODEL = st.secrets["MODEL_NAME"]
except: st.stop()

# --- æ ¸å¿ƒç®—æ³• ---

def get_embedding(text):
    # æ¨¡æ‹Ÿå‘é‡ (å®é™…åº”è°ƒç”¨ API)
    return np.random.rand(1536).tolist()

def cosine_similarity(v1, v2):
    vec1, vec2 = np.array(v1), np.array(v2)
    return np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2)) if np.linalg.norm(vec1) > 0 else 0

# ğŸŒŸ æ ¸å¿ƒä¿®å¤ï¼šè¡¥å…¨ calculate_rank å‡½æ•° (main.py åœ¨æ‰¾å®ƒ)
def calculate_rank(radar_data):
    if not radar_data: return "MSC å…¬æ°‘", "ğŸ¥‰"
    
    # å…¼å®¹å¤„ç†ï¼šå¦‚æœæ˜¯å­—ç¬¦ä¸²å°±è½¬å­—å…¸
    if isinstance(radar_data, str): 
        try:
            radar_data = json.loads(radar_data)
        except:
            return "MSC å…¬æ°‘", "ğŸ¥‰"
            
    # å®‰å…¨æ±‚å’Œ
    try:
        total = sum(float(v) for v in radar_data.values())
    except:
        total = 0
    
    # æ®µä½é€»è¾‘
    if total < 25: return "è§‚å¯Ÿè€…", "ğŸ¥‰"
    elif total < 38: return "æ¢ç´¢è€…", "ğŸ¥ˆ"
    elif total < 54: return "æ„å»ºè€…", "ğŸ’"
    else: return "é¢†èˆªå‘˜", "ğŸ‘‘"

# ğŸŒŸ æ ¸å¿ƒä¿®å¤ï¼šè¡¥å…¨ find_resonance
def find_resonance(current_vector, current_user, current_data):
    if not current_vector: return None
    # ä»æ•°æ®åº“è·å–å€™é€‰äºº
    others = db.get_resonance_candidates(current_user)
    if not others: return None
    
    best_match, highest_score = None, 0
    
    for row in others:
        if row['vector']:
            try:
                o_vec = json.loads(row['vector'])
                # ç®€å•è®¡ç®—ç›¸ä¼¼åº¦
                score = cosine_similarity(current_vector, o_vec)
                
                if score > config.RESONANCE_THRESHOLD and score > highest_score:
                    highest_score = score
                    best_match = {
                        "user": row['username'], 
                        "content": row['content'], 
                        "score": round(score * 100, 1)
                    }
            except: continue
    return best_match

# ğŸŒŸ æ ¸å¿ƒä¿®å¤ï¼šè¡¥å…¨ update_user_radar
def update_user_radar(username, input_scores):
    try:
        user_data = db.get_user_profile(username)
        current = user_data.get('radar_profile')
        if not current: 
            current = {k: 3.0 for k in input_scores.keys()}
        elif isinstance(current, str): 
            current = json.loads(current)
        
        updated = {}
        alpha = config.RADAR_ALPHA
        for k, v in input_scores.items():
            old_val = float(current.get(k, 3.0))
            new_val = float(v)
            updated[k] = round(old_val * 0.9 + new_val * 0.1, 2)
            
        db.update_radar_profile_db(username, json.dumps(updated))
    except: pass

# --- LLM è°ƒç”¨ ---
def call_ai_api(prompt):
    try:
        response = client_ai.chat.completions.create(
            model=TARGET_MODEL,
            messages=[{"role": "system", "content": "Output valid JSON only. No markdown."}, {"role": "user", "content": prompt}],
            temperature=0.7, stream=False, response_format={"type": "json_object"} 
        )
        content = response.choices[0].message.content
        try:
            match = re.search(r'\{.*\}', content, re.DOTALL)
            if match: return json.loads(match.group(0))
            else: return json.loads(content)
        except: return {"error": True}
    except Exception as e: return {"error": True, "msg": str(e)}

def get_normal_response(history_messages):
    try:
        api_messages = [{"role": "system", "content": config.PROMPT_CHATBOT}]
        for msg in history_messages: 
            if msg['role'] in ['user', 'assistant']:
                api_messages.append({"role": msg["role"], "content": msg["content"]})
        return client_ai.chat.completions.create(model=TARGET_MODEL, messages=api_messages, temperature=0.8, stream=True)
    except Exception as e: return str(e)

def analyze_meaning_background(text):
    prompt = f"{config.PROMPT_ANALYST}\nç”¨æˆ·è¾“å…¥: \"{text}\""
    res = call_ai_api(prompt)
    if res.get("valid", False):
        c = res.get('c_score', 0)
        n = res.get('n_score', 0)
        m = c * n * 2
        res['m_score'] = m
        if m < config.MEANING_THRESHOLD: res["valid"] = False
    return res

# å…¼å®¹æ—§å‡½æ•°å
analyze_meaning_engine = analyze_meaning_background

def generate_daily_question(username, radar_data):
    try:
        recent = db.get_user_nodes(username)
        ctx = ""
        if recent: 
            last_3 = recent[-3:]
            ctx = f"å…³æ³¨ç‚¹ï¼š{[n['care_point'] for n in last_3]}"
    except: ctx = ""

    radar_str = json.dumps(radar_data, ensure_ascii=False)
    prompt = f"{config.PROMPT_DAILY}\nç”¨æˆ·ï¼š{radar_str}ã€‚{ctx}ã€‚è¾“å‡º JSON: {{ 'question': '...' }}"
    res = call_ai_api(prompt)
    return res.get("question", "ä»Šå¤©ï¼Œä»€ä¹ˆäº‹æƒ…è®©ä½ æ„Ÿåˆ°'æ´»ç€'ï¼Ÿ")

def analyze_persona_report(radar_data):
    prompt = f"{config.PROMPT_PERSONA}\næ•°æ®ï¼š{json.dumps(radar_data)}ã€‚è¾“å‡º JSON: {{ 'static_portrait': '...', 'dynamic_growth': '...' }}"
    return call_ai_api(prompt)

def get_ai_interjection(history_text):
    prompt = f"{config.PROMPT_OBSERVER}\n{history_text}\nè¾“å‡º: çº¯æ–‡æœ¬"
    try: return client_ai.chat.completions.create(model=TARGET_MODEL, messages=[{"role": "user", "content": prompt}], temperature=0.9).choices[0].message.content
    except: return None
