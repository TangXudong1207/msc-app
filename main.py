import streamlit as st
from openai import OpenAI
from supabase import create_client, Client
from streamlit_echarts import st_echarts
import json
import re
import hashlib
import time
import numpy as np
from datetime import datetime

# ==========================================
# ğŸ›‘ æ ¸å¿ƒé…ç½®åŒº
# ==========================================

try:
    client_ai = OpenAI(
        api_key=st.secrets["API_KEY"],
        base_url=st.secrets["BASE_URL"]
    )
    TARGET_MODEL = st.secrets["MODEL_NAME"]

    SUPABASE_URL = st.secrets["SUPABASE_URL"]
    SUPABASE_KEY = st.secrets["SUPABASE_KEY"]
    supabase: Client = create_client(SUPABASE_URL, SUPABASE_KEY)

except Exception as e:
    st.error(f"ğŸš¨ é…ç½®é”™è¯¯: {str(e)}")
    st.stop()

# ==========================================
# ğŸ› ï¸ 1. åŸºç¡€è®¾æ–½å‡½æ•° (å…ˆå®šä¹‰ï¼Œé˜²æ­¢æŠ¥é”™)
# ==========================================

def make_hashes(password):
    return hashlib.sha256(str.encode(password)).hexdigest()

def check_hashes(password, hashed_text):
    if make_hashes(password) == hashed_text: return True
    return False

def add_user(username, password, nickname):
    try:
        res = supabase.table('users').select("*").eq('username', username).execute()
        if len(res.data) > 0: return False
        data = {"username": username, "password": make_hashes(password), "nickname": nickname}
        supabase.table('users').insert(data).execute()
        return True
    except: return False

def login_user(username, password):
    try:
        hashed_pw = make_hashes(password)
        res = supabase.table('users').select("*").eq('username', username).eq('password', hashed_pw).execute()
        return res.data
    except: return []

def get_nickname(username):
    try:
        res = supabase.table('users').select("nickname").eq('username', username).execute()
        if res.data: return res.data[0]['nickname']
        return username
    except: return username

# --- ğŸ’¾ æ•°æ®åº“å­˜å– (æ–°å¢ï¼šèŠå¤©è®°å½•) ---

def save_chat(username, role, content):
    """ä¿å­˜æ—¥å¸¸å¯¹è¯åˆ°æ•°æ®åº“"""
    try:
        data = {"username": username, "role": role, "content": content}
        supabase.table('chats').insert(data).execute()
    except Exception as e: print(f"Chat save error: {e}")

def get_chat_history(username, limit=50):
    """è·å–æœ€è¿‘çš„èŠå¤©è®°å½•"""
    try:
        # æŒ‰æ—¶é—´æ­£åºæ’åˆ—
        res = supabase.table('chats').select("*").eq('username', username).order('id', desc=False).limit(limit).execute()
        # ä¿®æ­£ï¼šå¦‚æœ limit ç”Ÿæ•ˆï¼Œå–å›æ¥çš„æ˜¯æœ€æ–°çš„Næ¡ï¼Œä½†é¡ºåºå¯èƒ½æ˜¯åçš„ï¼Œéœ€è¦ç¡®è®¤ desc=False å–çš„æ˜¯æœ€æ—§çš„è¿˜æ˜¯æœ€æ–°çš„
        # é€šå¸¸æˆ‘ä»¬å– desc=True (æœ€æ–°çš„50æ¡)ï¼Œç„¶ååè½¬åˆ—è¡¨æ˜¾ç¤º
        res = supabase.table('chats').select("*").eq('username', username).order('id', desc=True).limit(limit).execute()
        return list(reversed(res.data))
    except: return []

def save_node(username, content, data, mode, vector):
    """ä¿å­˜æ„ä¹‰èŠ‚ç‚¹"""
    try:
        logic = data.get('logic_score')
        if logic is None: logic = 0.5
        insert_data = {
            "username": username, "content": content,
            "care_point": data.get('care_point', 'æœªå‘½å'),
            "meaning_layer": data.get('meaning_layer', 'æš‚æ— ç»“æ„'),
            "insight": data.get('insight', 'ç”Ÿæˆä¸­æ–­'),
            "mode": mode, "vector": json.dumps(vector),
            "logic_score": logic, "keywords": json.dumps([])
        }
        supabase.table('nodes').insert(insert_data).execute()
        return True
    except: return False

def get_user_nodes(username):
    try:
        res = supabase.table('nodes').select("*").eq('username', username).order('id', desc=False).execute()
        return res.data
    except: return []

# ==========================================
# ğŸ§  2. AI æ ¸å¿ƒé€»è¾‘å‡½æ•°
# ==========================================

def get_embedding(text):
    return np.random.rand(1536).tolist()

def cosine_similarity(v1, v2):
    if not v1 or not v2: return 0
    vec1, vec2 = np.array(v1), np.array(v2)
    norm1, norm2 = np.linalg.norm(vec1), np.linalg.norm(vec2)
    if norm1 == 0 or norm2 == 0: return 0
    return np.dot(vec1, vec2) / (norm1 * norm2)

# --- èŠå¤©æœºå™¨äºº ---
def get_normal_response(history_messages):
    """
    æ™®é€šèŠå¤©æ¨¡å¼
    """
    try:
        api_messages = [{"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªæ¸©æš–ã€æ™ºæ…§çš„å¯¹è¯ä¼™ä¼´ã€‚è¯·ç”¨è‡ªç„¶ã€æµç•…çš„è¯­è¨€ä¸ç”¨æˆ·äº¤æµã€‚ä¸è¦è¾“å‡ºJSONã€‚"}]
        # è½¬æ¢æ•°æ®åº“æ ¼å¼åˆ° OpenAI æ ¼å¼
        for msg in history_messages:
            # è¿‡æ»¤æ‰é standard role
            role = msg['role'] if msg['role'] in ['user', 'assistant'] else 'user'
            api_messages.append({"role": role, "content": msg['content']})
        
        response = client_ai.chat.completions.create(
            model=TARGET_MODEL,
            messages=api_messages,
            temperature=0.8,
            stream=True 
        )
        return response
    except Exception as e:
        return f"ï¼ˆæ€è€ƒä¸­æ–­ï¼š{str(e)}ï¼‰"

# --- æ„ä¹‰åˆ†æå¸ˆ ---
def analyze_meaning_background(text):
    prompt = f"""
    ä»»åŠ¡ï¼šåˆ¤æ–­ç”¨æˆ·çš„è¿™å¥è¯æ˜¯å¦æœ‰æ·±å±‚æ„ä¹‰ã€‚
    è¾“å…¥ï¼š"{text}"
    åˆ¤æ–­æ ‡å‡†ï¼šå¿…é¡»åŒ…å«æ˜ç¡®è§‚ç‚¹ã€å¼ºçƒˆæƒ…ç»ªæˆ–ç‹¬ç‰¹æ´å¯Ÿã€‚åªæ˜¯å¯’æš„åˆ™è¿”å› {{ "valid": false }}ã€‚
    è‹¥ç¬¦åˆï¼Œè¯·æå–ç»“æ„å¹¶è¿”å› JSONï¼š
    {{
        "valid": true,
        "care_point": "ç®€çŸ­æ ¸å¿ƒå…³åˆ‡(10å­—å†…)",
        "meaning_layer": "å®Œæ•´ç»“æ„åˆ†æ...",
        "insight": "å‡ç»´æ´å¯Ÿé‡‘å¥...",
        "logic_score": 0.8
    }}
    """
    try:
        response = client_ai.chat.completions.create(
            model=TARGET_MODEL,
            messages=[{"role": "system", "content": "Output JSON only."}, {"role": "user", "content": prompt}],
            temperature=0.5, 
            response_format={"type": "json_object"}
        )
        content = response.choices[0].message.content
        return json.loads(content)
    except:
        return {"valid": False}

def generate_fusion(node_a_content, node_b_content):
    prompt = f"""
    èåˆ A: "{node_a_content}" å’Œ B: "{node_b_content}"ã€‚
    è¿”å›JSON:
    {{
        "care_point": "å…±åŒæ·±å±‚è¯‰æ±‚...",
        "meaning_layer": "å…¨æ™¯è§†è§’...",
        "insight": "å…¨æ–°æ´å¯Ÿ..."
    }}
    """
    try:
        response = client_ai.chat.completions.create(
            model=TARGET_MODEL,
            messages=[{"role": "system", "content": "Output JSON only."}, {"role": "user", "content": prompt}],
            temperature=0.7, response_format={"type": "json_object"} 
        )
        return json.loads(response.choices[0].message.content)
    except: return {"error": True}

def find_resonance(current_vector, current_user):
    if not current_vector: return None
    try:
        res = supabase.table('nodes').select("username, content, vector").neq('username', current_user).execute()
        others = res.data
        best_match, highest_score = None, 0
        for row in others:
            if row['vector']:
                try:
                    score = cosine_similarity(current_vector, json.loads(row['vector']))
                    if score > 0.75 and score > highest_score:
                        highest_score = score
                        best_match = {"user": row['username'], "content": row['content'], "score": round(score * 100, 1)}
                except: continue
        return best_match
    except: return None

# ==========================================
# ğŸ¨ 3. UI æ¸²æŸ“å‡½æ•°
# ==========================================

def render_constellation_map(nodes, height="350px", is_fullscreen=False):
    if not nodes:
        st.caption("å®‡å®™ä¸€ç‰‡å¯‚é™...")
        return

    graph_nodes = []
    graph_links = []
    categories = [{"name": "æ—¥å¸¸"}, {"name": "å­¦æœ¯"}, {"name": "è‰ºæœ¯"}]
    
    label_size = 14 if is_fullscreen else 10
    symbol_base = 30 if is_fullscreen else 15
    repulsion = 800 if is_fullscreen else 200

    for i, node in enumerate(nodes):
        logic = node.get('logic_score')
        if logic is None: logic = 0.5
        size = symbol_base * (0.8 + logic)
        cat_idx = 0
        if "å­¦æœ¯" in node['mode']: cat_idx = 1
        elif "è‰ºæœ¯" in node['mode']: cat_idx = 2
        
        graph_nodes.append({
            "name": str(node['id']),
            "id": str(node['id']),
            "symbolSize": size,
            "category": cat_idx,
            "value": node['care_point'],
            "label": {"show": is_fullscreen, "formatter": "{b}", "color": "#eee"},
            "vector": json.loads(node['vector']) if node.get('vector') else None
        })

    node_count = len(graph_nodes)
    for i in range(node_count):
        for j in range(i + 1, node_count):
            node_a, node_b = graph_nodes[i], graph_nodes[j]
            if node_a['vector'] and node_b['vector']:
                sim = cosine_similarity(node_a['vector'], node_b['vector'])
                if sim > 0.85:
                    graph_links.append({"source": node_a['id'], "target": node_b['id'], "lineStyle": {"width": 2, "color": "#00fff2"}})
                elif sim > 0.65:
                    graph_links.append({"source": node_a['id'], "target": node_b['id'], "lineStyle": {"width": 0.5, "color": "#555"}})

    option = {
        "backgroundColor": "#0e1117",
        "title": {"text": "ğŸŒŒ æ€æƒ³æ˜Ÿäº‘" if is_fullscreen else "", "left": "center", "textStyle": {"color": "#fff"}},
        "tooltip": {"trigger": "item", "formatter": "ID: {b}<br/>{c}"},
        "series": [{
            "type": "graph", "layout": "force", "data": graph_nodes, "links": graph_links, "categories": categories,
            "roam": True, "force": {"repulsion": repulsion, "gravity": 0.05, "edgeLength": [20, 100]},
            "itemStyle": {"shadowBlur": 10, "shadowColor": "rgba(255, 255, 255, 0.5)"}
        }]
    }
    st_echarts(options=option, height=height)

@st.dialog("ğŸ”­ æµ©è¡å®‡å®™ Â· è‡ªç”±æ˜Ÿäº‘", width="large")
def view_fullscreen_map(nodes):
    render_constellation_map(nodes, height="600px", is_fullscreen=True)

# ==========================================
# ğŸ–¥ï¸ 4. ä¸»ç¨‹åºå…¥å£
# ==========================================

st.set_page_config(page_title="MSC v17.0 Eternal Chat", layout="wide", initial_sidebar_state="expanded")

if "logged_in" not in st.session_state: st.session_state.logged_in = False

if not st.session_state.logged_in:
    col1, col2, col3 = st.columns([1,2,1])
    with col2:
        st.title("ğŸŒŒ MSC")
        st.caption("äººæœºå…±ç”Ÿ Â· æ„ä¹‰æ„å»ºç³»ç»Ÿ")
        tab1, tab2 = st.tabs(["ç™»å½•", "æ³¨å†Œ"])
        with tab1:
            u = st.text_input("ç”¨æˆ·å")
            p = st.text_input("å¯†ç ", type='password')
            if st.button("ç™»å½•", use_container_width=True):
                res = login_user(u, p)
                if res and len(res) > 0:
                    st.session_state.logged_in = True
                    st.session_state.username = u
                    st.session_state.nickname = res[0]['nickname']
                    st.rerun()
                else: st.error("è´¦å·æˆ–å¯†ç é”™è¯¯")
        with tab2:
            nu = st.text_input("æ–°ç”¨æˆ·å")
            np_pass = st.text_input("æ–°å¯†ç ", type='password')
            nn = st.text_input("æ˜µç§°")
            if st.button("æ³¨å†Œ", use_container_width=True):
                if add_user(nu, np_pass, nn): st.success("æ³¨å†ŒæˆåŠŸ")
                else: st.error("å¤±è´¥")

else:
    # --- æ•°æ®åŠ è½½ ---
    # 1. åŠ è½½èŠ‚ç‚¹å†å²ï¼ˆç”¨äºåœ°å›¾å’Œå³ä¾§æ‰¹æ³¨ï¼‰
    history_nodes = get_user_nodes(st.session_state.username)
    node_map = {node['content']: node for node in history_nodes} if history_nodes else {}
    
    # 2. åŠ è½½èŠå¤©å†å²ï¼ˆç”¨äºä¸­é—´å¯¹è¯æ¡†ï¼‰
    # æ³¨æ„ï¼šè¿™é‡Œæˆ‘ä»¬æ¯æ¬¡éƒ½ä»æ•°æ®åº“æ‹‰å–æœ€æ–°çš„ N æ¡ï¼Œä¿è¯ä¸ä¸¢å¤±
    chat_history = get_chat_history(st.session_state.username, limit=50)

    # --- ä¾§è¾¹æ  ---
    with st.sidebar:
        st.caption(f"å½“å‰ç”¨æˆ·: {st.session_state.nickname}")
        if st.button("é€€å‡º"):
            st.session_state.logged_in = False
            st.rerun()
        st.divider()
        st.caption("ğŸŒ å…¨å±€æ‹“æ‰‘")
        render_constellation_map(history_nodes, height="300px")
        if st.button("ğŸ”­ å…¨å±æ˜Ÿäº‘", use_container_width=True):
            view_fullscreen_map(history_nodes)

    # --- ä¸»ç•Œé¢å¸ƒå±€ ---
    col_chat, col_insight = st.columns([0.7, 0.3], gap="large")

    # --- 1. å·¦ä¾§ï¼šèŠå¤©æµ ---
    with col_chat:
        st.subheader("ğŸ’¬ æ„ä¹‰æµ")
        
        # æ¸²æŸ“æ•°æ®åº“é‡Œçš„å†å²è®°å½•
        for msg in chat_history:
            with st.chat_message(msg['role']):
                st.markdown(msg['content'], unsafe_allow_html=True)
                # è¿™é‡Œæš‚æ—¶ä¸æ¸²æŸ“å†å²å…±é¸£æŒ‰é’®ï¼Œé¿å…ç•Œé¢å¤ªä¹±ï¼Œåªåœ¨å®æ—¶äº¤äº’æ—¶å‡ºç°

        # è¾“å…¥å¤„ç†
        if prompt := st.chat_input("è¾“å…¥æ€è€ƒ..."):
            # A. ç«‹å³æ˜¾ç¤ºå¹¶ä¿å­˜ç”¨æˆ·æ¶ˆæ¯
            with st.chat_message("user"):
                st.markdown(prompt)
            save_chat(st.session_state.username, "user", prompt)

            # B. ç”Ÿæˆå¹¶ä¿å­˜åŠ©æ‰‹å›å¤
            with st.chat_message("assistant"):
                # ä¼ å…¥å½“å‰å†å²ä¸Šä¸‹æ–‡ï¼ˆåŒ…å«åˆšå­˜å…¥çš„é‚£æ¡ï¼‰
                # ä¸ºäº†æµå¼æ•ˆæœï¼Œæˆ‘ä»¬ç›´æ¥è°ƒç”¨ AIï¼Œä¸é‡æ–°æ‹‰æ•°æ®åº“
                stream_response = get_normal_response(chat_history + [{'role':'user', 'content':prompt}])
                response_text = st.write_stream(stream_response)
            save_chat(st.session_state.username, "assistant", response_text)
            
            # C. å¼‚æ­¥è¿›è¡Œæ„ä¹‰åˆ†æ
            with st.spinner("âš¡ è§£æä¸­..."):
                analysis = analyze_meaning_background(prompt)
                
                if analysis.get("valid", False):
                    vec = get_embedding(prompt)
                    save_node(st.session_state.username, prompt, analysis, "æ—¥å¸¸", vec)
                    
                    # å¯»æ‰¾å…±é¸£
                    match = find_resonance(vec, st.session_state.username)
                    if match:
                        msg_id = int(time.time())
                        # æŠŠå…±é¸£æç¤ºä¹Ÿä½œä¸ºä¸€æ¡ assistant æ¶ˆæ¯å­˜è¿›å»ï¼Ÿ
                        # æˆ–è€…åªå­˜å…¥ Session ä¾›æœ¬æ¬¡æ˜¾ç¤ºï¼Ÿ
                        # è¿™é‡Œä¸ºäº†ç®€å•ï¼Œæˆ‘ä»¬åªåœ¨ç•Œé¢æ˜¾ç¤ºï¼Œä¸å­˜å…¥ chat è¡¨ï¼Œå› ä¸ºå®ƒæ˜¯ä¸€ç§â€œç³»ç»Ÿé€šçŸ¥â€
                        st.toast(f"ğŸ”” å‘ç°ä¸ {match['user']} çš„å…±é¸£ï¼", icon="âš¡")
                        # (ç”±äº Streamlit åˆ·æ–°æœºåˆ¶ï¼Œè¿™é‡Œä¸å¥½ç›´æ¥æ’æŒ‰é’®ï¼Œ
                        # æˆ‘ä»¬ä¾èµ– rerun åï¼Œåœ¨å³ä¾§æˆ–è€…æ–°çš„ä¸€è¡Œæ˜¾ç¤ºã€‚
                        # ä¸ºäº†æ¼”ç¤ºæ–¹ä¾¿ï¼Œæˆ‘ä»¬æš‚æ—¶ä¸å­˜åº“å…±é¸£äº‹ä»¶ï¼Œä»…åˆ·æ–°æ˜¾ç¤ºèŠ‚ç‚¹)
                
                # åˆ·æ–°é¡µé¢ï¼Œè®©å³ä¾§çš„èŠ‚ç‚¹å¡ç‰‡æ˜¾ç¤ºå‡ºæ¥
                st.rerun()

    # --- 2. å³ä¾§ï¼šæ‰¹æ³¨æµ ---
    with col_insight:
        # åªæ˜¾ç¤ºä¸å½“å‰å±å¹•ä¸Šçš„å¯¹è¯åŒ¹é…çš„èŠ‚ç‚¹
        # å€’åºéå†èŠå¤©è®°å½•ï¼Œæ‰¾åˆ°æœ‰èŠ‚ç‚¹çš„
        
        # ä¸ºäº†ç¾è§‚ï¼Œæˆ‘ä»¬åªæ˜¾ç¤ºæœ€è¿‘ç”Ÿæˆçš„å‡ ä¸ªèŠ‚ç‚¹ï¼Œæˆ–è€…åŒ¹é…åˆ°çš„
        st.caption("ğŸ§© æ·±åº¦æ‰¹æ³¨")
        
        # æˆ‘ä»¬å¯ä»¥æ˜¾ç¤ºæ‰€æœ‰å†å²èŠ‚ç‚¹ï¼Œæˆ–è€…åªæ˜¾ç¤ºå’Œå½“å‰å¯¹è¯æœ‰å…³çš„
        # è¿™é‡Œæ˜¾ç¤ºæ‰€æœ‰å†å²èŠ‚ç‚¹çš„æŠ˜å æ¿ï¼ŒæŒ‰æ—¶é—´å€’åº
        for node in reversed(history_nodes):
            with st.expander(f"âœ¨ #{node['id']} {node['care_point'][:6]}...", expanded=False):
                st.caption(f"Logic: {node.get('logic_score', 0.5)}")
                st.write(f"**Structure:** {node['meaning_layer']}")
                st.info(f"ğŸ’¡ {node['insight']}")
