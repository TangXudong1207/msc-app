import streamlit as st
from openai import OpenAI
from supabase import create_client, Client
from streamlit_echarts import st_echarts
import json
import re
import hashlib
import time
import numpy as np
from datetime import datetime

# ==========================================
# ğŸ›‘ æ ¸å¿ƒé…ç½®åŒº
# ==========================================

try:
    client = OpenAI(
        api_key=st.secrets["API_KEY"],
        base_url=st.secrets["BASE_URL"]
    )
    TARGET_MODEL = st.secrets["MODEL_NAME"]

    SUPABASE_URL = st.secrets["SUPABASE_URL"]
    SUPABASE_KEY = st.secrets["SUPABASE_KEY"]
    supabase: Client = create_client(SUPABASE_URL, SUPABASE_KEY)

except Exception as e:
    st.error(f"ğŸš¨ é…ç½®é”™è¯¯: {str(e)}")
    st.stop()

# ==========================================

# --- ğŸ† æ¸¸æˆåŒ–ï¼šæ®µä½è®¡ç®—ç³»ç»Ÿ ---
def calculate_rank(radar_data):
    """
    æ ¹æ®é›·è¾¾å›¾æ€»åˆ†è®¡ç®—æ®µä½
    7ä¸ªç»´åº¦ï¼Œæ¯ä¸ªç»´åº¦æœ€é«˜10åˆ†ï¼Œæ»¡åˆ†70åˆ†ã€‚
    """
    if not radar_data: return "å€”å¼ºé’é“œ III", "ğŸ¥‰"
    
    total_score = sum(radar_data.values())
    
    # æ®µä½é˜ˆå€¼è®¾è®¡
    if total_score < 25: return "å€”å¼ºé’é“œ", "ğŸ¥‰"
    elif total_score < 30: return "ç§©åºç™½é“¶", "ğŸ¥ˆ"
    elif total_score < 38: return "è£è€€é»„é‡‘", "ğŸ¥‡"
    elif total_score < 46: return "å°Šè´µé“‚é‡‘", "ğŸ’"
    elif total_score < 54: return "æ°¸æ’é’»çŸ³", "ğŸ’ "
    elif total_score < 62: return "è‡³å°Šæ˜Ÿè€€", "âœ¨"
    else: return "æœ€å¼ºç‹è€…", "ğŸ‘‘"

# --- ğŸ› ï¸ åŸºç¡€è®¾æ–½ ---
def make_hashes(password):
    return hashlib.sha256(str.encode(password)).hexdigest()

def check_hashes(password, hashed_text):
    if make_hashes(password) == hashed_text: return True
    return False

def add_user(username, password, nickname):
    try:
        res = supabase.table('users').select("*").eq('username', username).execute()
        if len(res.data) > 0: return False
        # åˆå§‹åŒ–ï¼šå…¨éƒ¨ 3.0 åˆ†
        default_radar = {
            "Care": 3.0, "Curiosity": 3.0, "Reflection": 3.0, "Coherence": 3.0,
            "Empathy": 3.0, "Agency": 3.0, "Aesthetic": 3.0
        }
        data = {"username": username, "password": make_hashes(password), "nickname": nickname, "radar_profile": json.dumps(default_radar)}
        supabase.table('users').insert(data).execute()
        return True
    except: return False

def login_user(username, password):
    try:
        hashed_pw = make_hashes(password)
        res = supabase.table('users').select("*").eq('username', username).eq('password', hashed_pw).execute()
        return res.data
    except: return []

def get_user_profile(username):
    try:
        res = supabase.table('users').select("nickname, radar_profile").eq('username', username).execute()
        if res.data: return res.data[0]
    except: pass
    return {"nickname": username, "radar_profile": None}

def update_radar_score(username, new_scores):
    try:
        user_data = get_user_profile(username)
        current_radar = user_data.get('radar_profile')
        if not current_radar:
            current_radar = {k: 3.0 for k in new_scores.keys()}
        elif isinstance(current_radar, str):
            current_radar = json.loads(current_radar)
            
        alpha = 0.08 # ç¨å¾®è°ƒé«˜å­¦ä¹ ç‡ï¼Œè®©å‡çº§å¿«ä¸€ç‚¹ç‚¹
        updated_radar = {}
        for key in new_scores:
            old_val = float(current_radar.get(key, 3.0))
            input_val = float(new_scores.get(key, 0))
            if input_val > 1.0:
                updated_val = old_val * (1 - alpha) + input_val * alpha
                updated_radar[key] = round(min(10.0, updated_val), 2)
            else:
                updated_radar[key] = old_val

        supabase.table('users').update({"radar_profile": json.dumps(updated_radar)}).eq("username", username).execute()
        return updated_radar
    except Exception as e: return None

# --- ğŸ§  AI æ ¸å¿ƒ ---
def call_ai_api(prompt):
    try:
        response = client.chat.completions.create(
            model=TARGET_MODEL,
            messages=[{"role": "system", "content": "Output valid JSON only."}, {"role": "user", "content": prompt}],
            temperature=0.7, stream=False, response_format={"type": "json_object"} 
        )
        content = response.choices[0].message.content
        try:
            match = re.search(r'\{.*\}', content, re.DOTALL)
            if match: return json.loads(match.group(0))
            else: return json.loads(content)
        except: return {"error": True, "msg": "JSONè§£æå¤±è´¥"}
    except Exception as e: return {"error": True, "msg": str(e)}

def analyze_persona_report(radar_data):
    """
    ç”Ÿæˆäººç‰©ç”»åƒåˆ†ææŠ¥å‘Š
    """
    radar_str = json.dumps(radar_data, ensure_ascii=False)
    prompt = f"""
    ä»»åŠ¡ï¼šåŸºäºç”¨æˆ·çš„å…ƒäººæ€§é›·è¾¾æ•°æ®ï¼Œç”Ÿæˆä¸€ä»½æ·±åº¦äººç‰©ç”»åƒã€‚
    é›·è¾¾æ•°æ®ï¼š{radar_str}
    
    è¯·è¾“å‡º JSON æ ¼å¼ï¼š
    {{
        "static_portrait": "é™æ€ç”»åƒï¼šç”¨å¿ƒç†å­¦å’Œå“²å­¦è¯­è¨€æè¿°è¯¥ç”¨æˆ·çš„æ ¸å¿ƒäººæ ¼åº•è‰²ã€ä¼˜åŠ¿ä¸ç›²ç‚¹...",
        "dynamic_growth": "åŠ¨æ€æˆé•¿ï¼šåˆ†æè¯¥ç”¨æˆ·ç›®å‰çš„è¿›åŒ–è¶‹åŠ¿ï¼Œå¹¶ç»™å‡ºä¸‹ä¸€æ­¥æå‡æ®µä½çš„å…·ä½“å»ºè®®..."
    }}
    """
    return call_ai_api(prompt)

def get_embedding(text):
    return np.random.rand(1536).tolist()

def get_normal_response(history_messages):
    try:
        api_messages = [{"role": "system", "content": "ä½ æ˜¯æ¸©æš–çš„å¯¹è¯ä¼™ä¼´ã€‚"}]
        for msg in history_messages:
            api_messages.append({"role": msg["role"], "content": msg["content"]})
        response = client.chat.completions.create(
            model=TARGET_MODEL, messages=api_messages, temperature=0.8, stream=True 
        )
        return response
    except Exception as e: return f"Error: {e}"

def analyze_meaning_background(text):
    prompt = f"""
    åˆ†æè¾“å…¥ï¼š"{text}"
    1. åˆ¤æ–­æ˜¯å¦ç”ŸæˆèŠ‚ç‚¹ã€‚
    2. æå– MSC ç»“æ„ã€‚
    3. ã€é›·è¾¾è¯„åˆ†ã€‘è¯·å¯¹è¿™æ®µè¯ä½“ç°çš„ç»´åº¦æ‰“åˆ†(0-10)ï¼š
       Care, Curiosity, Reflection, Coherence, Empathy, Agency, Aestheticã€‚
    
    è¿”å› JSON:
    {{
        "valid": true,
        "care_point": "...", "meaning_layer": "...", "insight": "...",
        "logic_score": 0.8, "keywords": [],
        "radar_scores": {{ "Care": 7, "Curiosity": 5, ... }}
    }}
    """
    return call_ai_api(prompt)

def generate_fusion(node_a_content, node_b_content):
    prompt = f"""
    èåˆ A: "{node_a_content}" B: "{node_b_content}"ã€‚
    è¿”å› JSON: {{ "care_point": "...", "meaning_layer": "...", "insight": "..." }}
    """
    return call_ai_api(prompt)

# --- æ•°æ®åº“ä¸ç®—æ³• (ä¿æŒä¸å˜) ---
def save_chat(username, role, content):
    try:
        data = {"username": username, "role": role, "content": content, "is_deleted": False}
        supabase.table('chats').insert(data).execute()
    except: pass

def get_active_chats(username, limit=50):
    try:
        res = supabase.table('chats').select("*").eq('username', username).eq('is_deleted', False).order('id', desc=True).limit(limit).execute()
        return list(reversed(res.data))
    except: return []

def soft_delete_chat_and_node(chat_id, content, username):
    try:
        supabase.table('chats').update({"is_deleted": True}).eq("id", chat_id).execute()
        supabase.table('nodes').update({"is_deleted": True}).eq("username", username).eq("content", content).execute()
        return True
    except: return False

def save_node(username, content, data, mode, vector):
    try:
        logic = data.get('logic_score', 0.5)
        keywords = data.get('keywords', [])
        insert_data = {
            "username": username, "content": content,
            "care_point": data.get('care_point', 'æœªå‘½å'),
            "meaning_layer": data.get('meaning_layer', 'æš‚æ— ç»“æ„'),
            "insight": data.get('insight', 'ç”Ÿæˆä¸­æ–­'),
            "mode": mode, "vector": json.dumps(vector),
            "logic_score": logic, "keywords": json.dumps(keywords), "is_deleted": False
        }
        supabase.table('nodes').insert(insert_data).execute()
        return True
    except: return False

def get_active_nodes_map(username):
    try:
        res = supabase.table('nodes').select("*").eq('username', username).eq('is_deleted', False).execute()
        return {node['content']: node for node in res.data}
    except: return {}

def get_all_nodes_for_map(username):
    try:
        res = supabase.table('nodes').select("*").eq('username', username).eq('is_deleted', False).order('id', desc=False).execute()
        return res.data
    except: return []

def cosine_similarity(v1, v2):
    vec1, vec2 = np.array(v1), np.array(v2)
    return np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2)) if np.linalg.norm(vec1) > 0 else 0

def find_resonance(current_vector, current_user):
    if not current_vector: return None
    try:
        res = supabase.table('nodes').select("*").neq('username', current_user).eq('is_deleted', False).execute()
        best_match, highest = None, 0
        for row in res.data:
            if row['vector']:
                try:
                    score = cosine_similarity(current_vector, json.loads(row['vector']))
                    if score > 0.75 and score > highest:
                        highest = score
                        best_match = {"user": row['username'], "content": row['content'], "score": round(score * 100, 1)}
                except: continue
        return best_match
    except: return None

# --- ğŸ¨ æ¸²æŸ“å‡½æ•° ---

def render_radar_chart(radar_dict, height="300px"):
    keys = ["Care", "Curiosity", "Reflection", "Coherence", "Empathy", "Agency", "Aesthetic"]
    scores = [radar_dict.get(k, 3.0) for k in keys]
    
    option = {
        "backgroundColor": "transparent",
        "radar": {
            "indicator": [{"name": k, "max": 10} for k in keys],
            "splitNumber": 4,
            "axisName": {"color": "#bbb"},
            "splitLine": {"lineStyle": {"color": ["#333", "#444", "#555", "#666"]}},
            "splitArea": {"show": False}
        },
        "series": [{
            "type": "radar",
            "data": [{
                "value": scores,
                "name": "Meta-Humanity",
                "areaStyle": {"color": "rgba(0, 255, 242, 0.4)"},
                "lineStyle": {"color": "#00fff2", "width": 2},
                "itemStyle": {"color": "#fff"}
            }]
        }]
    }
    st_echarts(options=option, height=height)

def render_cyberpunk_map(nodes, height="250px", is_fullscreen=False):
    if not nodes: return
    graph_nodes, graph_links = [], []
    symbol_base = 30 if is_fullscreen else 15
    repulsion = 1000 if is_fullscreen else 300

    for i, node in enumerate(nodes):
        logic = node.get('logic_score', 0.5)
        graph_nodes.append({
            "name": str(node['id']),
            "id": str(node['id']),
            "symbolSize": symbol_base * (0.8 + logic),
            "value": node['care_point'],
            "label": {"show": is_fullscreen, "formatter": node['care_point'][:5], "color": "#fff"},
            "vector": json.loads(node['vector']) if node.get('vector') else None,
            "keywords": json.loads(node['keywords']) if node.get('keywords') else []
        })

    node_count = len(graph_nodes)
    for i in range(node_count):
        for j in range(i + 1, node_count):
            na, nb = graph_nodes[i], graph_nodes[j]
            if na['vector'] and nb['vector']:
                m_inter = len(set(na['keywords']).intersection(set(nb['keywords'])))
                m_union = len(set(na['keywords']).union(set(nb['keywords'])))
                m_sim = m_inter / m_union if m_union > 0 else 0
                vec_sim = cosine_similarity(na['vector'], nb['vector'])
                score = 0.6 * m_sim + 0.4 * vec_sim
                if score > 0.8:
                    graph_links.append({"source": na['name'], "target": nb['name'], "lineStyle": {"width": 2, "color": "#00fff2"}})
                elif score > 0.6:
                    graph_links.append({"source": na['name'], "target": nb['name'], "lineStyle": {"width": 0.5, "color": "#555", "type": "dashed"}})

    option = {
        "backgroundColor": "#0e1117",
        "series": [{
            "type": "graph", "layout": "force", "data": graph_nodes, "links": graph_links,
            "roam": True, "force": {"repulsion": repulsion, "gravity": 0.05},
            "itemStyle": {"shadowBlur": 10, "shadowColor": "rgba(255, 255, 255, 0.5)"}
        }]
    }
    st_echarts(options=option, height=height)

# --- ğŸ–¥ï¸ å¼¹çª— Dialog ---
@st.dialog("ğŸ”­ æµ©è¡å®‡å®™", width="large")
def view_fullscreen_map(nodes):
    render_cyberpunk_map(nodes, height="600px", is_fullscreen=True)

@st.dialog("ğŸ§¬ å…ƒäººæ€§è¿›åŒ–é¢æ¿", width="large")
def view_radar_details(radar_dict):
    rank, icon = calculate_rank(radar_dict)
    
    c1, c2 = st.columns([1, 2])
    with c1:
        st.markdown(f"### {icon} {rank}")
        total = sum(radar_dict.values())
        st.metric("æ€»çµåŠ›å€¼", f"{total:.1f} / 70")
        st.caption("éšä½ çš„æ€æƒ³æ·±åº¦åŠ¨æ€ç”Ÿé•¿")
    
    with c2:
        render_radar_chart(radar_dict, height="250px")

    st.divider()
    st.subheader("ğŸ“Š ç»´åº¦è§£æ")
    
    cols = st.columns(4)
    keys = list(radar_dict.keys())
    for i, k in enumerate(keys):
        with cols[i % 4]:
            val = radar_dict[k]
            st.metric(k, f"{val:.1f}", delta=None)
            st.progress(val / 10)

    st.markdown("---")
    
    # ğŸ”¥ AI ç”»åƒåˆ†ææŒ‰é’®
    if st.button("ğŸ¤– ç”Ÿæˆäººç‰©ç”»åƒåˆ†æ", type="primary", use_container_width=True):
        with st.spinner("DeepSeek æ­£åœ¨æ‰«ææ‚¨çš„çµé­‚ç»“æ„..."):
            analysis = analyze_persona_report(radar_dict)
            if "error" not in analysis:
                st.success("åˆ†æå®Œæˆ")
                st.markdown(f"### ğŸ–¼ï¸ é™æ€ç”»åƒ")
                st.write(analysis.get('static_portrait', 'æ— æ•°æ®'))
                st.markdown(f"### ğŸš€ åŠ¨æ€æˆé•¿")
                st.write(analysis.get('dynamic_growth', 'æ— æ•°æ®'))
            else:
                st.error("åˆ†æå¤±è´¥ï¼Œè¯·é‡è¯•")

# ==========================================
# ğŸ–¥ï¸ ä¸»ç¨‹åº
# ==========================================

st.set_page_config(page_title="MSC v21.0 Rank", layout="wide", initial_sidebar_state="expanded")

if "logged_in" not in st.session_state: st.session_state.logged_in = False

if not st.session_state.logged_in:
    st.title("ğŸŒŒ MSC")
    # Login UI (omitted)
    tab1, tab2 = st.tabs(["ç™»å½•", "æ³¨å†Œ"])
    with tab1:
        u = st.text_input("ç”¨æˆ·å")
        p = st.text_input("å¯†ç ", type='password')
        if st.button("ç™»å½•"):
            res = login_user(u, p)
            if res:
                st.session_state.logged_in = True
                st.session_state.username = u
                st.session_state.nickname = res[0]['nickname']
                st.session_state.messages = [] 
                st.rerun()
            else: st.error("é”™è¯¯")
    with tab2:
        nu = st.text_input("æ–°ç”¨æˆ·å")
        np_pass = st.text_input("æ–°å¯†ç ", type='password')
        nn = st.text_input("æ˜µç§°")
        if st.button("æ³¨å†Œ"):
            if add_user(nu, np_pass, nn): st.success("æˆåŠŸ")
            else: st.error("å¤±è´¥")

else:
    chat_history = get_active_chats(st.session_state.username)
    nodes_map = get_active_nodes_map(st.session_state.username)
    all_nodes_list = get_all_nodes_for_map(st.session_state.username)
    user_profile = get_user_profile(st.session_state.username)
    
    # å¤„ç†é›·è¾¾æ•°æ®
    raw_radar = user_profile.get('radar_profile')
    if isinstance(raw_radar, str): radar_dict = json.loads(raw_radar)
    elif isinstance(raw_radar, dict): radar_dict = raw_radar
    else: radar_dict = {k:3.0 for k in ["Care", "Curiosity", "Reflection", "Coherence", "Empathy", "Agency", "Aesthetic"]}

    with st.sidebar:
        # ğŸŒŸ æ¸¸æˆåŒ–å…¥å£
        rank_name, rank_icon = calculate_rank(radar_dict)
        st.markdown(f"## {rank_icon} {st.session_state.nickname}")
        st.caption(f"å½“å‰æ®µä½: **{rank_name}**")
        
        # é›·è¾¾å›¾ (ç‚¹å‡»æ”¾å¤§)
        render_radar_chart(radar_dict, height="200px")
        if st.button("ğŸ“ˆ æŸ¥çœ‹è¿›åŒ–é¢æ¿", use_container_width=True):
            view_radar_details(radar_dict)
            
        st.divider()
        c1, c2 = st.columns(2)
        if c1.button("ğŸ—‘ï¸ å›æ”¶ç«™"): st.toast("åŠŸèƒ½ç»´æŠ¤ä¸­...")
        if c2.button("é€€å‡º"): st.session_state.logged_in = False; st.rerun()
        st.divider()
        render_cyberpunk_map(all_nodes_list, height="200px")
        if st.button("ğŸ”­ å…¨å±æ˜Ÿäº‘", use_container_width=True): view_fullscreen_map(all_nodes_list)

    st.subheader("ğŸ’¬ æ„ä¹‰æµ")
    
    for msg in chat_history:
        col_chat, col_node = st.columns([0.65, 0.35], gap="small")
        with col_chat:
            c_msg, c_del = st.columns([0.9, 0.1])
            with c_msg:
                with st.chat_message(msg['role']): st.markdown(msg['content'], unsafe_allow_html=True)
            with c_del:
                if msg['role'] == 'user':
                    if st.button("âœ•", key=f"del_{msg['id']}"):
                        if soft_delete_chat_and_node(msg['id'], msg['content'], st.session_state.username): st.rerun()
            if msg.get('role') == 'assistant' and "ğŸ§¬ èåˆæˆåŠŸ" in msg['content']: pass 

        with col_node:
            if msg['role'] == 'user' and msg['content'] in nodes_map:
                node = nodes_map[msg['content']]
                with st.expander(f"âœ¨ {node['care_point']}", expanded=False):
                    st.caption(f"Logic: {node.get('logic_score', 0.5)}")
                    st.markdown(f"**Insight:** {node['insight']}")
                    st.markdown(f"**Structure:**\n{node['meaning_layer']}")
                    st.caption(f"Time: {node['created_at'][:16]}")

    if prompt := st.chat_input("è¾“å…¥..."):
        save_chat(st.session_state.username, "user", prompt)
        
        full_history = chat_history + [{'role':'user', 'content':prompt}]
        stream = get_normal_response(full_history)
        reply_text = st.write_stream(stream)
        save_chat(st.session_state.username, "assistant", reply_text)
        
        with st.spinner("âš¡ æ„ä¹‰åˆ¤åˆ«..."):
            analysis = analyze_meaning_background(prompt)
            if analysis.get("valid", False):
                vec = get_embedding(prompt)
                save_node(st.session_state.username, prompt, analysis, "æ—¥å¸¸", vec)
                
                # æ›´æ–°é›·è¾¾å¹¶è®¡ç®—æ–°æ®µä½
                if "radar_scores" in analysis:
                    update_radar_score(st.session_state.username, analysis["radar_scores"])
                
                match = find_resonance(vec, st.session_state.username)
                if match: st.toast(f"ğŸ”” å‘ç°å…±é¸£ï¼", icon="âš¡")
        
        st.rerun()
