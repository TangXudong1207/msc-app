import streamlit as st
from openai import OpenAI
from supabase import create_client, Client
from streamlit_echarts import st_echarts
import json
import re
import hashlib
import time
import numpy as np
from datetime import datetime
from sklearn.decomposition import PCA # ğŸŒŸ æ–°å¢ï¼šç”¨äºæŠŠé«˜ç»´æ€æƒ³é™ç»´æˆ3Dåæ ‡
from sklearn.cluster import KMeans    # ğŸŒŸ æ–°å¢ï¼šç”¨äºå¯»æ‰¾æ˜Ÿäº‘èšç±»

# ==========================================
# ğŸ›‘ æ ¸å¿ƒé…ç½®åŒº
# ==========================================

try:
    client = OpenAI(
        api_key=st.secrets["API_KEY"],
        base_url=st.secrets["BASE_URL"]
    )
    TARGET_MODEL = st.secrets["MODEL_NAME"]

    SUPABASE_URL = st.secrets["SUPABASE_URL"]
    SUPABASE_KEY = st.secrets["SUPABASE_KEY"]
    supabase: Client = create_client(SUPABASE_URL, SUPABASE_KEY)

except Exception as e:
    st.error(f"ğŸš¨ é…ç½®é”™è¯¯: {str(e)}")
    st.stop()

# ==========================================

# --- ğŸ› ï¸ åŸºç¡€è®¾æ–½ ---
def make_hashes(password):
    return hashlib.sha256(str.encode(password)).hexdigest()

def check_hashes(password, hashed_text):
    if make_hashes(password) == hashed_text: return True
    return False

def add_user(username, password, nickname):
    try:
        res = supabase.table('users').select("*").eq('username', username).execute()
        if len(res.data) > 0: return False
        data = {"username": username, "password": make_hashes(password), "nickname": nickname}
        supabase.table('users').insert(data).execute()
        return True
    except: return False

def login_user(username, password):
    try:
        hashed_pw = make_hashes(password)
        res = supabase.table('users').select("*").eq('username', username).eq('password', hashed_pw).execute()
        return res.data
    except: return []

def get_nickname(username):
    try:
        res = supabase.table('users').select("nickname").eq('username', username).execute()
        if res.data: return res.data[0]['nickname']
        return username
    except: return username

# --- ğŸ’¾ æ•°æ®åº“æ“ä½œ ---
def save_chat(username, role, content):
    try:
        data = {"username": username, "role": role, "content": content, "is_deleted": False}
        supabase.table('chats').insert(data).execute()
    except: pass

def get_active_chats(username, limit=50):
    try:
        res = supabase.table('chats').select("*").eq('username', username).eq('is_deleted', False).order('id', desc=True).limit(limit).execute()
        return list(reversed(res.data))
    except: return []

def soft_delete_chat_and_node(chat_id, content, username):
    try:
        supabase.table('chats').update({"is_deleted": True}).eq("id", chat_id).execute()
        supabase.table('nodes').update({"is_deleted": True}).eq("username", username).eq("content", content).execute()
        return True
    except: return False

def save_node(username, content, data, mode, vector):
    try:
        logic = data.get('logic_score')
        if logic is None: logic = 0.5
        keywords = data.get('keywords', [])
        
        insert_data = {
            "username": username, "content": content,
            "care_point": data.get('care_point', 'æœªå‘½å'),
            "meaning_layer": data.get('meaning_layer', 'æš‚æ— ç»“æ„'),
            "insight": data.get('insight', 'ç”Ÿæˆä¸­æ–­'),
            "mode": mode, "vector": json.dumps(vector),
            "logic_score": logic, "keywords": json.dumps(keywords), "is_deleted": False
        }
        supabase.table('nodes').insert(insert_data).execute()
        return True
    except: return False

def get_active_nodes_map(username):
    try:
        res = supabase.table('nodes').select("*").eq('username', username).eq('is_deleted', False).execute()
        return {node['content']: node for node in res.data}
    except: return {}

def get_all_nodes_for_map(username):
    try:
        res = supabase.table('nodes').select("*").eq('username', username).eq('is_deleted', False).order('id', desc=False).execute()
        return res.data
    except: return []

# æ–°å¢ï¼šè·å–å…¨ç½‘æ‰€æœ‰èŠ‚ç‚¹ï¼ˆä¸ºäº†æ„å»ºå¤§æ˜Ÿç©ºï¼‰
def get_global_nodes():
    try:
        # é™åˆ¶å–æœ€æ–°çš„200ä¸ªèŠ‚ç‚¹ï¼Œé˜²æ­¢è®¡ç®—é‡è¿‡å¤§ç‚¸å†…å­˜
        res = supabase.table('nodes').select("*").eq('is_deleted', False).order('id', desc=True).limit(200).execute()
        return res.data
    except: return []

# --- ğŸ§  AI æ ¸å¿ƒ ---
def call_ai_api(prompt):
    try:
        response = client.chat.completions.create(
            model=TARGET_MODEL,
            messages=[{"role": "system", "content": "Output valid JSON only. Do not use markdown blocks."}, {"role": "user", "content": prompt}],
            temperature=0.7, stream=False, response_format={"type": "json_object"} 
        )
        content = response.choices[0].message.content
        try:
            match = re.search(r'\{.*\}', content, re.DOTALL)
            if match: return json.loads(match.group(0))
            else: return json.loads(content)
        except: return {"error": True, "msg": "JSONè§£æå¤±è´¥"}
    except Exception as e: return {"error": True, "msg": str(e)}

def get_embedding(text):
    return np.random.rand(1536).tolist()

def get_normal_response(history_messages):
    try:
        api_messages = [{"role": "system", "content": "ä½ æ˜¯æ¸©æš–çš„å¯¹è¯ä¼™ä¼´ã€‚"}]
        for msg in history_messages:
            api_messages.append({"role": msg["role"], "content": msg["content"]})
        response = client.chat.completions.create(
            model=TARGET_MODEL, messages=api_messages, temperature=0.8, stream=True 
        )
        return response
    except Exception as e: return f"Error: {e}"

def analyze_meaning_background(text):
    prompt = f"""
    åˆ†æè¾“å…¥ï¼š"{text}"
    1. åˆ¤æ–­æ˜¯å¦ç”ŸæˆèŠ‚ç‚¹ (valid: true/false)ã€‚åªæœ‰å…·å¤‡æ·±å±‚è§‚ç‚¹æˆ–æƒ…ç»ªæ‰ç”Ÿæˆã€‚
    2. æå– Topic Tags (è¡¨å±‚è¯é¢˜)ã€‚
    3. æå– Meaning Tags (æ·±å±‚ä»·å€¼)ã€‚
    4. æå– Care Point (ç®€çŸ­å…³åˆ‡)ã€‚
    5. æå– Meaning Layer (ç»“æ„åˆ†æ)ã€‚
    6. æå– Insight (å‡ç»´æ´å¯Ÿ)ã€‚
    
    è¿”å› JSON:
    {{
        "valid": true,
        "care_point": "...",
        "meaning_layer": "...",
        "insight": "...",
        "logic_score": 0.8,
        "keywords": ["tag1", "tag2"], 
        "topic_tags": ["topic1", "topic2"],
        "existential_q": false
    }}
    """
    return call_ai_api(prompt)

def generate_fusion(node_a_content, node_b_content):
    prompt = f"""
    ä»»åŠ¡ï¼šåŸºäº Deep Meaning å…±é¸£è¿›è¡Œèåˆã€‚
    A: "{node_a_content}"
    B: "{node_b_content}"
    è¿”å› JSON: {{ "care_point": "...", "meaning_layer": "...", "insight": "..." }}
    """
    return call_ai_api(prompt)

# --- ğŸ§® ç®—æ³• ---
def cosine_similarity(v1, v2):
    vec1, vec2 = np.array(v1), np.array(v2)
    return np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2)) if np.linalg.norm(vec1) > 0 else 0

def find_resonance(current_vector, current_user):
    if not current_vector: return None
    try:
        res = supabase.table('nodes').select("*").neq('username', current_user).eq('is_deleted', False).execute()
        others = res.data
        best_match, highest_score = None, 0
        for row in others:
            if row['vector']:
                try:
                    score = cosine_similarity(current_vector, json.loads(row['vector']))
                    if score > 0.75 and score > highest_score:
                        highest_score = score
                        best_match = {"user": row['username'], "content": row['content'], "score": round(score * 100, 1)}
                except: continue
        return best_match
    except: return None

# --- ğŸŒ 3D åœ°çƒä¸æ˜Ÿç©ºæ¸²æŸ“ (ä¸Šå¸è§†è§’) ---

def render_3d_earth(nodes):
    """
    åœ°çƒå¤œæ™¯æ¨¡å¼ï¼šæ¨¡æ‹ŸèŠ‚ç‚¹åœ¨å…¨çƒçš„åˆ†å¸ƒ
    """
    # æ¨¡æ‹Ÿæ•°æ®ï¼šå› ä¸ºæ²¡æœ‰çœŸå®IPï¼Œæˆ‘ä»¬éšæœºç”Ÿæˆä¸€äº›ä¸–ç•Œä¸»è¦åŸå¸‚çš„åæ ‡
    # æ ¼å¼ï¼š[ç»åº¦, çº¬åº¦, äº®åº¦]
    data = []
    for _ in range(len(nodes) + 10): # åŸºç¡€ç‚¹ + èŠ‚ç‚¹ç‚¹
        # éšæœºåˆ†å¸ƒåœ¨åŒ—åŠçƒä¸»è¦åŒºåŸŸï¼Œæ¨¡æ‹Ÿäººç±»æ´»åŠ¨
        lon = np.random.uniform(-130, 150) 
        lat = np.random.uniform(-30, 60)
        value = np.random.randint(10, 100)
        data.append([lon, lat, value])

    option = {
        "backgroundColor": "#000",
        "globe": {
            "baseTexture": "https://echarts.apache.org/examples/data-gl/asset/earth.jpg",
            "heightTexture": "https://echarts.apache.org/examples/data-gl/asset/bathymetry_bw_composite_4k.jpg",
            "displacementScale": 0.1,
            "shading": "lambert",
            "environment": "https://echarts.apache.org/examples/data-gl/asset/starfield.jpg",
            "light": {"ambient": {"intensity": 0.4}, "main": {"intensity": 0.4}},
            "viewControl": {"autoRotate": True}
        },
        "series": [{
            "type": "scatter3D",
            "coordinateSystem": "globe",
            "data": data,
            "symbolSize": 5,
            "itemStyle": {"color": "#ffaa00", "opacity": 0.8}, # é‡‘è‰²ç¯å…‰
            "blendMode": "lighter"
        }]
    }
    st_echarts(options=option, height="500px")

def render_3d_galaxy(nodes):
    """
    æ„ä¹‰æ˜Ÿæ²³æ¨¡å¼ï¼šä½¿ç”¨ PCA é™ç»´ï¼Œå±•ç¤ºè¯­ä¹‰ç»“æ„
    """
    if len(nodes) < 5:
        st.warning("ğŸŒŒ æ˜Ÿè¾°æ•°é‡ä¸è¶³ï¼Œæ— æ³•èšåˆæˆæ˜Ÿç³»ã€‚è¯·å¤šç”Ÿæˆå‡ ä¸ªæ„ä¹‰èŠ‚ç‚¹ï¼ˆè‡³å°‘5ä¸ªï¼‰ã€‚")
        return

    # 1. å‡†å¤‡å‘é‡æ•°æ®
    vectors = []
    labels = []
    
    for node in nodes:
        if node['vector']:
            try:
                v = json.loads(node['vector'])
                vectors.append(v)
                labels.append(node['care_point'])
            except: pass
    
    if not vectors: return

    # 2. æ ¸å¿ƒæ•°å­¦ï¼šPCA é™ç»´ (1536ç»´ -> 3ç»´)
    # è¿™å°±æ˜¯æŠŠâ€œæ„ä¹‰â€å˜æˆâ€œç©ºé—´åæ ‡â€çš„è¿‡ç¨‹
    pca = PCA(n_components=3)
    coords = pca.fit_transform(vectors)
    
    # 3. æ ¸å¿ƒæ•°å­¦ï¼šK-Means èšç±» (å¯»æ‰¾æ˜Ÿäº‘ä¸­å¿ƒ)
    # æˆ‘ä»¬å‡è®¾æœ‰ 3 ä¸ªä¸»è¦æ˜Ÿäº‘ (Hope, Responsibility, etc.)
    n_clusters = min(3, len(vectors))
    kmeans = KMeans(n_clusters=n_clusters)
    clusters = kmeans.fit_predict(vectors)
    
    # 4. æ„å»ºå›¾è¡¨æ•°æ®
    scatter_data = []
    
    # é¢œè‰²æ˜ å°„
    colors = ["#ff0000", "#00ff00", "#0000ff", "#ffff00", "#00ffff"]
    
    for i, (x, y, z) in enumerate(coords):
        cluster_id = clusters[i]
        scatter_data.append({
            "name": labels[i],
            "value": [x, y, z, cluster_id], # ç¬¬4ç»´æ˜¯é¢œè‰²åˆ†ç±»
            "itemStyle": {"color": colors[cluster_id % len(colors)]}
        })

    option = {
        "backgroundColor": "#000",
        "tooltip": {},
        "visualMap": {
            "show": False,
            "dimension": 3,
            "min": 0,
            "max": n_clusters,
            "inRange": {"color": ["#313695", "#4575b4", "#74add1", "#abd9e9", "#e0f3f8", "#ffffbf", "#fee090", "#fdae61", "#f46d43", "#d73027", "#a50026"]}
        },
        "xAxis3D": {"type": "value", "show": False},
        "yAxis3D": {"type": "value", "show": False},
        "zAxis3D": {"type": "value", "show": False},
        "grid3D": {
            "viewControl": {"autoRotate": True, "projection": "perspective"},
            "axisLine": {"lineStyle": {"color": "#fff"}},
            "splitLine": {"show": False}
        },
        "series": [{
            "type": "scatter3D",
            "data": scatter_data,
            "symbolSize": 10,
            "label": {
                "show": True, # æ˜¾ç¤ºå…³é”®è¯ï¼
                "formatter": "{b}", # æ˜¾ç¤º Care Point
                "textStyle": {"color": "white", "fontSize": 10, "backgroundColor": "rgba(0,0,0,0.5)"}
            }
        }]
    }
    st_echarts(options=option, height="600px")

# --- ä¾§è¾¹æ å°åœ°å›¾ ---
def render_cyberpunk_map(nodes, height="250px", is_fullscreen=False):
    # ... (ä¿æŒåŸæ ·ï¼Œçœç•¥ä»¥èŠ‚çœç©ºé—´) ...
    if not nodes: return
    graph_nodes, graph_links = [], []
    for i, node in enumerate(nodes):
        logic = node.get('logic_score')
        if logic is None: logic = 0.5
        graph_nodes.append({
            "name": str(node['id']), "id": str(node['id']),
            "symbolSize": (30 if is_fullscreen else 15) * (0.8 + logic),
            "value": node['care_point'],
            "label": {"show": is_fullscreen, "formatter": node['care_point'][:5], "color": "#fff"},
            "vector": json.loads(node['vector']) if node.get('vector') else None,
            "keywords": json.loads(node['keywords']) if node.get('keywords') else []
        })
    node_count = len(graph_nodes)
    for i in range(node_count):
        for j in range(i + 1, node_count):
            na, nb = graph_nodes[i], graph_nodes[j]
            if na['vector'] and nb['vector']:
                m_sim = len(set(na['keywords']).intersection(set(nb['keywords']))) / (len(set(na['keywords']).union(set(nb['keywords']))) or 1)
                vec_sim = cosine_similarity(na['vector'], nb['vector'])
                score = 0.6 * m_sim + 0.4 * vec_sim
                if score > 0.8: graph_links.append({"source": na['name'], "target": nb['name'], "lineStyle": {"width": 2, "color": "#00fff2"}})
                elif score > 0.6: graph_links.append({"source": na['name'], "target": nb['name'], "lineStyle": {"width": 0.5, "color": "#555", "type": "dashed"}})
    option = {
        "backgroundColor": "#0e1117",
        "series": [{"type": "graph", "layout": "force", "data": graph_nodes, "links": graph_links, "roam": True, "force": {"repulsion": 1000 if is_fullscreen else 300}, "itemStyle": {"shadowBlur": 10}}]
    }
    st_echarts(options=option, height=height)

@st.dialog("ğŸ”­ æµ©è¡å®‡å®™", width="large")
def view_fullscreen_map(nodes):
    render_cyberpunk_map(nodes, height="600px", is_fullscreen=True)

@st.dialog("ğŸŒ MSC World Â· ä¸Šå¸è§†è§’", width="large")
def view_msc_world():
    # 1. è·å–å…¨ç½‘æ•°æ®
    global_nodes = get_global_nodes()
    
    tab1, tab2 = st.tabs(["ğŸŒ åœ°çƒå¤œæ™¯ (Earth)", "ğŸŒŒ æ„ä¹‰æ˜Ÿæ²³ (Galaxy)"])
    
    with tab1:
        st.caption("è¿™é‡Œå±•ç¤ºäº†å…¨çƒ MSC èŠ‚ç‚¹çš„æ´»è·ƒåˆ†å¸ƒï¼ˆæ¨¡æ‹Ÿæ•°æ®ï¼‰ã€‚")
        render_3d_earth(global_nodes)
    
    with tab2:
        st.caption("è¿™æ˜¯å…¨äººç±»æ„ä¹‰çš„æ‹“æ‰‘ç»“æ„ã€‚ç›¸ä¼¼çš„æ€æƒ³æ±‡èšæˆæ˜Ÿäº‘ï¼Œå­¤ç‹¬çš„æ€æƒ³æˆä¸ºå­¤æ˜Ÿã€‚")
        if len(global_nodes) > 3:
            render_3d_galaxy(global_nodes)
        else:
            st.info("æ˜Ÿç³»æ­£åœ¨åç¼©ä¸­... éœ€è¦æ›´å¤šæ•°æ®æ‰èƒ½å½¢æˆæ˜Ÿäº‘ã€‚")

# ==========================================
# ğŸ–¥ï¸ ä¸»ç¨‹åº
# ==========================================

st.set_page_config(page_title="MSC v22.0 World", layout="wide", initial_sidebar_state="expanded")

if "logged_in" not in st.session_state: st.session_state.logged_in = False

if not st.session_state.logged_in:
    st.title("ğŸŒŒ MSC")
    # ... Login UI ...
    tab1, tab2 = st.tabs(["ç™»å½•", "æ³¨å†Œ"])
    with tab1:
        u = st.text_input("ç”¨æˆ·å")
        p = st.text_input("å¯†ç ", type='password')
        if st.button("ç™»å½•", use_container_width=True):
            res = login_user(u, p)
            if res and len(res) > 0:
                st.session_state.logged_in = True
                st.session_state.username = u
                st.session_state.nickname = res[0]['nickname']
                st.session_state.messages = [] 
                st.rerun()
            else: st.error("é”™è¯¯")
    with tab2:
        nu = st.text_input("æ–°ç”¨æˆ·å")
        np_pass = st.text_input("æ–°å¯†ç ", type='password')
        nn = st.text_input("æ˜µç§°")
        if st.button("æ³¨å†Œ", use_container_width=True):
            if add_user(nu, np_pass, nn): st.success("æˆåŠŸ")
            else: st.error("å¤±è´¥")

else:
    chat_history = get_active_chats(st.session_state.username)
    nodes_map = get_active_nodes_map(st.session_state.username)
    all_nodes_list = get_all_nodes_for_map(st.session_state.username)

    with st.sidebar:
        st.write(f"ğŸ‘‹ **{st.session_state.nickname}**")
        c1, c2 = st.columns(2)
        
        # ğŸŒŸ æ ¸å¿ƒå…¥å£ï¼šMSC World
        if st.button("ğŸŒ MSC World", use_container_width=True, type="primary"):
            view_msc_world()
            
        if c2.button("é€€å‡º"): st.session_state.logged_in = False; st.rerun()
        
        st.divider()
        st.caption("æˆ‘çš„å°å®‡å®™")
        render_cyberpunk_map(all_nodes_list, height="200px")
        if st.button("ğŸ”­ å…¨å±", use_container_width=True): view_fullscreen_map(all_nodes_list)

    st.subheader("ğŸ’¬ æ„ä¹‰æµ")
    # ... (Chat logic same as before) ...
    for msg in chat_history:
        col_chat, col_node = st.columns([0.65, 0.35], gap="small")
        with col_chat:
            c_msg, c_del = st.columns([0.9, 0.1])
            with c_msg:
                with st.chat_message(msg['role']): st.markdown(msg['content'], unsafe_allow_html=True)
            with c_del:
                if msg['role'] == 'user':
                    if st.button("âœ•", key=f"del_{msg['id']}"):
                        if soft_delete_chat_and_node(msg['id'], msg['content'], st.session_state.username): st.rerun()
            if msg.get('role') == 'assistant' and "ğŸ§¬ èåˆæˆåŠŸ" in msg['content']: pass 

        with col_node:
            if msg['role'] == 'user' and msg['content'] in nodes_map:
                node = nodes_map[msg['content']]
                with st.expander(f"âœ¨ {node['care_point']}", expanded=False):
                    st.caption(f"MLS Logic: {node.get('logic_score', 0.5)}")
                    st.markdown(f"**Insight:** {node['insight']}")
                    st.markdown(f"**Structure:**\n{node['meaning_layer']}")
                    st.caption(f"Time: {node['created_at'][:16]}")

    if prompt := st.chat_input("è¾“å…¥..."):
        save_chat(st.session_state.username, "user", prompt)
        full_history = chat_history + [{'role':'user', 'content':prompt}]
        stream = get_normal_response(full_history)
        reply_text = st.write_stream(stream)
        save_chat(st.session_state.username, "assistant", reply_text)
        
        with st.spinner("âš¡ æ„ä¹‰åˆ¤åˆ«..."):
            analysis = analyze_meaning_background(prompt)
            if analysis.get("valid", False):
                vec = get_embedding(prompt)
                save_node(st.session_state.username, prompt, analysis, "æ—¥å¸¸", vec)
                match = find_resonance(vec, st.session_state.username)
                if match: st.toast(f"ğŸ”” å‘ç°å…±é¸£ï¼", icon="âš¡")
        st.rerun()
