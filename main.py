import streamlit as st
from openai import OpenAI
from supabase import create_client, Client
from streamlit_echarts import st_echarts
import json
import re
import hashlib
import time
import numpy as np
from datetime import datetime

# ==========================================
# ğŸ›‘ æ ¸å¿ƒé…ç½®åŒº
# ==========================================

try:
    client = OpenAI(
        api_key=st.secrets["API_KEY"],
        base_url=st.secrets["BASE_URL"]
    )
    TARGET_MODEL = st.secrets["MODEL_NAME"]

    SUPABASE_URL = st.secrets["SUPABASE_URL"]
    SUPABASE_KEY = st.secrets["SUPABASE_KEY"]
    supabase: Client = create_client(SUPABASE_URL, SUPABASE_KEY)

except Exception as e:
    st.error(f"ğŸš¨ é…ç½®é”™è¯¯: {str(e)}")
    st.stop()

# ==========================================

# --- ğŸ› ï¸ åŸºç¡€è®¾æ–½ ---
def make_hashes(password):
    return hashlib.sha256(str.encode(password)).hexdigest()

def add_user(username, password, nickname):
    try:
        res = supabase.table('users').select("*").eq('username', username).execute()
        if len(res.data) > 0: return False
        # åˆå§‹åŒ–é›·è¾¾å›¾ï¼šæ‰€æœ‰ç»´åº¦é»˜è®¤ 3.0 åˆ† (æ»¡åˆ†10åˆ†)
        default_radar = {
            "Care": 3.0, "Curiosity": 3.0, "Reflection": 3.0, "Coherence": 3.0,
            "Empathy": 3.0, "Agency": 3.0, "Aesthetic": 3.0
        }
        data = {
            "username": username, 
            "password": make_hashes(password), 
            "nickname": nickname,
            "radar_profile": json.dumps(default_radar)
        }
        supabase.table('users').insert(data).execute()
        return True
    except: return False

def login_user(username, password):
    try:
        hashed_pw = make_hashes(password)
        res = supabase.table('users').select("*").eq('username', username).eq('password', hashed_pw).execute()
        return res.data
    except: return []

def get_user_profile(username):
    """è·å–ç”¨æˆ·ä¿¡æ¯ï¼ŒåŒ…æ‹¬é›·è¾¾æ•°æ®"""
    try:
        res = supabase.table('users').select("nickname, radar_profile").eq('username', username).execute()
        if res.data:
            return res.data[0]
    except: pass
    return {"nickname": username, "radar_profile": None}

def update_radar_score(username, new_scores):
    """
    å…ƒäººæ€§ç”Ÿé•¿ç®—æ³•ï¼š
    æ–°å€¼ = æ—§å€¼ * 0.95 + æœ¬æ¬¡å¾—åˆ† * 0.05
    è®©é›·è¾¾å›¾å‘ˆç°â€œç¼“æ…¢ç”Ÿé•¿â€çš„ç”Ÿç‰©ç‰¹æ€§ï¼Œè€Œä¸æ˜¯å‰§çƒˆè·³åŠ¨ã€‚
    """
    try:
        # 1. è·å–æ—§æ•°æ®
        user_data = get_user_profile(username)
        current_radar = user_data.get('radar_profile')
        
        if not current_radar:
            current_radar = {k: 3.0 for k in new_scores.keys()}
        elif isinstance(current_radar, str):
            current_radar = json.loads(current_radar)
            
        # 2. è®¡ç®—è¿›åŒ–
        alpha = 0.05 # å­¦ä¹ ç‡ï¼Œè¶Šå°è¶Šç¨³å®š
        updated_radar = {}
        for key in new_scores:
            old_val = float(current_radar.get(key, 3.0))
            input_val = float(new_scores.get(key, 0))
            # åªæœ‰å½“æœ¬æ¬¡è¾“å…¥åœ¨è¯¥ç»´åº¦æœ‰æ˜¾è‘—è¡¨ç°(>1)æ—¶æ‰æ›´æ–°ï¼Œé¿å…è¢«æ— æ•ˆå¯¹è¯ç¨€é‡Š
            if input_val > 1.0:
                updated_val = old_val * (1 - alpha) + input_val * alpha
                updated_radar[key] = round(min(10.0, updated_val), 2)
            else:
                updated_radar[key] = old_val # ä¿æŒä¸å˜

        # 3. å­˜å›æ•°æ®åº“
        supabase.table('users').update({"radar_profile": json.dumps(updated_radar)}).eq("username", username).execute()
        return updated_radar
    except Exception as e:
        print(f"Radar update error: {e}")
        return None

# --- ğŸ’¾ æ•°æ®åº“æ“ä½œ ---
def save_chat(username, role, content):
    try:
        data = {"username": username, "role": role, "content": content, "is_deleted": False}
        supabase.table('chats').insert(data).execute()
    except: pass

def get_active_chats(username, limit=50):
    try:
        res = supabase.table('chats').select("*").eq('username', username).eq('is_deleted', False).order('id', desc=True).limit(limit).execute()
        return list(reversed(res.data))
    except: return []

def soft_delete_chat_and_node(chat_id, content, username):
    try:
        supabase.table('chats').update({"is_deleted": True}).eq("id", chat_id).execute()
        supabase.table('nodes').update({"is_deleted": True}).eq("username", username).eq("content", content).execute()
        return True
    except: return False

def save_node(username, content, data, mode, vector):
    try:
        logic = data.get('logic_score')
        if logic is None: logic = 0.5
        keywords = data.get('keywords', [])
        
        insert_data = {
            "username": username, "content": content,
            "care_point": data.get('care_point', 'æœªå‘½å'),
            "meaning_layer": data.get('meaning_layer', 'æš‚æ— ç»“æ„'),
            "insight": data.get('insight', 'ç”Ÿæˆä¸­æ–­'),
            "mode": mode, "vector": json.dumps(vector),
            "logic_score": logic, "is_deleted": False,
            "keywords": json.dumps(keywords)
        }
        supabase.table('nodes').insert(insert_data).execute()
        return True
    except: return False

def get_active_nodes_map(username):
    try:
        res = supabase.table('nodes').select("*").eq('username', username).eq('is_deleted', False).execute()
        return {node['content']: node for node in res.data}
    except: return {}

def get_all_nodes_for_map(username):
    try:
        res = supabase.table('nodes').select("*").eq('username', username).eq('is_deleted', False).order('id', desc=False).execute()
        return res.data
    except: return []

# --- ğŸ§  AI æ ¸å¿ƒ (å…ƒäººæ€§å‡çº§ç‰ˆ) ---
def call_ai_api(prompt):
    try:
        response = client.chat.completions.create(
            model=TARGET_MODEL,
            messages=[{"role": "system", "content": "You are a profound philosopher. Output valid JSON only. Do not use markdown blocks."}, {"role": "user", "content": prompt}],
            temperature=0.7, stream=False, response_format={"type": "json_object"} 
        )
        content = response.choices[0].message.content
        try:
            match = re.search(r'\{.*\}', content, re.DOTALL)
            if match: return json.loads(match.group(0))
            else: return json.loads(content)
        except: return {"error": True, "msg": "JSONè§£æå¤±è´¥"}
    except Exception as e: return {"error": True, "msg": str(e)}

def get_embedding(text):
    return np.random.rand(1536).tolist()

def get_normal_response(history_messages):
    try:
        api_messages = [{"role": "system", "content": "ä½ æ˜¯æ¸©æš–çš„å¯¹è¯ä¼™ä¼´ã€‚"}]
        for msg in history_messages:
            api_messages.append({"role": msg["role"], "content": msg["content"]})
        response = client.chat.completions.create(
            model=TARGET_MODEL, messages=api_messages, temperature=0.8, stream=True 
        )
        return response
    except Exception as e: return f"Error: {e}"

def analyze_meaning_background(text):
    # ğŸŒŸ æ ¸å¿ƒå‡çº§ï¼šå¢åŠ å…ƒäººæ€§é›·è¾¾è¯„åˆ†
    prompt = f"""
    åˆ†æè¾“å…¥ï¼š"{text}"
    
    1. åˆ¤æ–­æ˜¯å¦æœ‰æ·±å±‚æ„ä¹‰ (valid: true/false)ã€‚
    2. æå– MSC ç»“æ„ (care_point, meaning_layer, insight)ã€‚
    
    3. ã€å…ƒäººæ€§è¯„åˆ† (Meta-Humanity Radar)ã€‘
    è¯·å¯¹è¿™æ®µè¯èƒŒåçš„ç”ŸæˆåŠ¨æœºè¿›è¡Œè¯„åˆ† (0-10åˆ†)ï¼š
    - Care (åœ¨ä¹åŠ›): æƒ…æ„ŸæŠ•å…¥ã€è´£ä»»æ„Ÿã€å¯¹ä»·å€¼çš„æ‰§ç€ã€‚
    - Curiosity (æ¢ç´¢æ¬²): å¯¹æœªçŸ¥çš„è¿½é—®ã€å‘ç°å†²åŠ¨ã€‚
    - Reflection (åæ€åŠ›): è´¨ç–‘è‡ªèº«ã€å‘å†…å®¡è§†ã€‚
    - Coherence (ç»“æ„åŒ–): é€»è¾‘æ¸…æ™°ã€ä½“ç³»åŒ–ç¨‹åº¦ã€‚
    - Empathy (å…±æ„ŸåŠ›): å¯¹ä»–äººæˆ–ä¸–ç•Œçš„å…±æƒ…ã€‚
    - Agency (è¡ŒåŠ¨åŠ›): å°†æ„ä¹‰è½¬åŒ–ä¸ºè¡ŒåŠ¨çš„å€¾å‘ã€‚
    - Aesthetic (å®¡ç¾åŠ›): å¯¹å’Œè°ã€ç¾æ„Ÿã€è¯—æ„çš„æ•é”åº¦ã€‚
    
    è¿”å› JSON:
    {{
        "valid": true,
        "care_point": "...",
        "meaning_layer": "...",
        "insight": "...",
        "logic_score": 0.8,
        "keywords": ["tag1", "tag2"],
        "radar_scores": {{
            "Care": 8, "Curiosity": 5, "Reflection": 7, 
            "Coherence": 6, "Empathy": 4, "Agency": 2, "Aesthetic": 3
        }}
    }}
    """
    return call_ai_api(prompt)

def generate_fusion(node_a_content, node_b_content):
    prompt = f"""
    ä»»åŠ¡ï¼šåŸºäº Deep Meaning å…±é¸£è¿›è¡Œèåˆã€‚
    A: "{node_a_content}"
    B: "{node_b_content}"
    è¿”å› JSON: {{ "care_point": "...", "meaning_layer": "...", "insight": "..." }}
    """
    return call_ai_api(prompt)

def cosine_similarity(v1, v2):
    vec1, vec2 = np.array(v1), np.array(v2)
    return np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2)) if np.linalg.norm(vec1) > 0 else 0

def find_resonance(current_vector, current_user):
    if not current_vector: return None
    try:
        res = supabase.table('nodes').select("*").neq('username', current_user).eq('is_deleted', False).execute()
        others = res.data
        best_match, highest_score = None, 0
        for row in others:
            if row['vector']:
                try:
                    score = cosine_similarity(current_vector, json.loads(row['vector']))
                    if score > 0.75 and score > highest_score:
                        highest_score = score
                        best_match = {"user": row['username'], "content": row['content'], "score": round(score * 100, 1)}
                except: continue
        return best_match
    except: return None

# --- ğŸ¨ æ¸²æŸ“å‡½æ•° ---

def render_radar_chart(profile_data):
    """æ¸²æŸ“å…ƒäººæ€§é›·è¾¾å›¾"""
    if not profile_data or not profile_data.get('radar_profile'):
        scores = [3,3,3,3,3,3,3] # é»˜è®¤å€¼
    else:
        # å¤„ç† JSON å­—ç¬¦ä¸²
        radar_json = profile_data['radar_profile']
        if isinstance(radar_json, str):
            radar_dict = json.loads(radar_json)
        else:
            radar_dict = radar_json
            
        # æå–7ä¸ªç»´åº¦çš„å€¼
        keys = ["Care", "Curiosity", "Reflection", "Coherence", "Empathy", "Agency", "Aesthetic"]
        scores = [radar_dict.get(k, 3.0) for k in keys]

    option = {
        "backgroundColor": "transparent",
        "radar": {
            "indicator": [
                {"name": "Care\nåœ¨ä¹", "max": 10},
                {"name": "Curiosity\næ¢ç´¢", "max": 10},
                {"name": "Reflection\nåæ€", "max": 10},
                {"name": "Coherence\nç»“æ„", "max": 10},
                {"name": "Empathy\nå…±æ„Ÿ", "max": 10},
                {"name": "Agency\nè¡ŒåŠ¨", "max": 10},
                {"name": "Aesthetic\nå®¡ç¾", "max": 10}
            ],
            "splitNumber": 4,
            "axisName": {"color": "#bbb"},
            "splitLine": {"lineStyle": {"color": ["#333", "#444", "#555", "#666"]}},
            "splitArea": {"show": False}
        },
        "series": [{
            "type": "radar",
            "data": [{
                "value": scores,
                "name": "Meta-Humanity",
                "areaStyle": {"color": "rgba(0, 255, 242, 0.4)"}, # èµ›åšé’
                "lineStyle": {"color": "#00fff2", "width": 2},
                "itemStyle": {"color": "#fff"}
            }]
        }]
    }
    st_echarts(options=option, height="300px")

def render_cyberpunk_map(nodes, height="250px", is_fullscreen=False):
    if not nodes: return
    graph_nodes, graph_links = [], []
    symbol_base = 30 if is_fullscreen else 15
    repulsion = 1000 if is_fullscreen else 300

    for i, node in enumerate(nodes):
        logic = node.get('logic_score', 0.5)
        graph_nodes.append({
            "name": str(node['id']),
            "id": str(node['id']),
            "symbolSize": symbol_base * (0.8 + logic),
            "value": node['care_point'],
            "label": {"show": is_fullscreen, "formatter": node['care_point'][:5], "color": "#fff"},
            "vector": json.loads(node['vector']) if node.get('vector') else None,
            "keywords": json.loads(node['keywords']) if node.get('keywords') else []
        })

    node_count = len(graph_nodes)
    for i in range(node_count):
        for j in range(i + 1, node_count):
            na, nb = graph_nodes[i], graph_nodes[j]
            if na['vector'] and nb['vector']:
                m_inter = len(set(na['keywords']).intersection(set(nb['keywords'])))
                m_union = len(set(na['keywords']).union(set(nb['keywords'])))
                m_sim = m_inter / m_union if m_union > 0 else 0
                vec_sim = cosine_similarity(na['vector'], nb['vector'])
                score = 0.6 * m_sim + 0.4 * vec_sim
                if score > 0.8:
                    graph_links.append({"source": na['name'], "target": nb['name'], "lineStyle": {"width": 2, "color": "#00fff2"}})
                elif score > 0.6:
                    graph_links.append({"source": na['name'], "target": nb['name'], "lineStyle": {"width": 0.5, "color": "#555", "type": "dashed"}})

    option = {
        "backgroundColor": "#0e1117",
        "series": [{
            "type": "graph", "layout": "force", "data": graph_nodes, "links": graph_links,
            "roam": True, "force": {"repulsion": repulsion, "gravity": 0.05},
            "itemStyle": {"shadowBlur": 10, "shadowColor": "rgba(255, 255, 255, 0.5)"}
        }]
    }
    st_echarts(options=option, height=height)

@st.dialog("ğŸ”­ æµ©è¡å®‡å®™", width="large")
def view_fullscreen_map(nodes):
    render_cyberpunk_map(nodes, height="600px", is_fullscreen=True)

# ==========================================
# ğŸ–¥ï¸ ä¸»ç¨‹åº
# ==========================================

st.set_page_config(page_title="MSC v20.0 Radar", layout="wide", initial_sidebar_state="expanded")

if "logged_in" not in st.session_state: st.session_state.logged_in = False

if not st.session_state.logged_in:
    st.title("ğŸŒŒ MSC")
    # Login... (omitted for brevity, same as v19)
    tab1, tab2 = st.tabs(["ç™»å½•", "æ³¨å†Œ"])
    with tab1:
        u = st.text_input("ç”¨æˆ·å")
        p = st.text_input("å¯†ç ", type='password')
        if st.button("ç™»å½•", use_container_width=True):
            res = login_user(u, p)
            if res and len(res) > 0:
                st.session_state.logged_in = True
                st.session_state.username = u
                st.session_state.nickname = res[0]['nickname']
                st.session_state.messages = [] 
                st.rerun()
            else: st.error("é”™è¯¯")
    with tab2:
        nu = st.text_input("æ–°ç”¨æˆ·å")
        np_pass = st.text_input("æ–°å¯†ç ", type='password')
        nn = st.text_input("æ˜µç§°")
        if st.button("æ³¨å†Œ", use_container_width=True):
            if add_user(nu, np_pass, nn): st.success("æˆåŠŸ")
            else: st.error("å¤±è´¥")

else:
    chat_history = get_active_chats(st.session_state.username)
    nodes_map = get_active_nodes_map(st.session_state.username)
    all_nodes_list = get_all_nodes_for_map(st.session_state.username)
    # è·å–ç”¨æˆ·ç”»åƒï¼ˆåŒ…å«é›·è¾¾æ•°æ®ï¼‰
    user_profile = get_user_profile(st.session_state.username)

    with st.sidebar:
        st.write(f"ğŸ‘‹ **{st.session_state.nickname}**")
        
        # ğŸŒŸ æ ¸å¿ƒæ–°åŠŸèƒ½ï¼šå…ƒäººæ€§é›·è¾¾å›¾
        st.caption("ğŸ§¬ å…ƒäººæ€§é›·è¾¾ (Meta-Humanity Radar)")
        render_radar_chart(user_profile)
        
        c1, c2 = st.columns(2)
        if c1.button("ğŸ—‘ï¸ å›æ”¶ç«™"): st.toast("åŠŸèƒ½ç»´æŠ¤ä¸­...")
        if c2.button("é€€å‡º"): st.session_state.logged_in = False; st.rerun()
        
        st.divider()
        st.caption("ğŸŒ æ€æƒ³æ˜Ÿäº‘")
        render_cyberpunk_map(all_nodes_list, height="200px")
        if st.button("ğŸ”­ å…¨å±æ˜Ÿäº‘", use_container_width=True): view_fullscreen_map(all_nodes_list)

    st.subheader("ğŸ’¬ æ„ä¹‰æµ")
    
    for msg in chat_history:
        col_chat, col_node = st.columns([0.65, 0.35], gap="small")
        with col_chat:
            c_msg, c_del = st.columns([0.9, 0.1])
            with c_msg:
                with st.chat_message(msg['role']): st.markdown(msg['content'])
            with c_del:
                if msg['role'] == 'user':
                    if st.button("âœ•", key=f"del_{msg['id']}"):
                        if soft_delete_chat_and_node(msg['id'], msg['content'], st.session_state.username): st.rerun()
            
            if msg.get('role') == 'assistant' and "ğŸ§¬ èåˆæˆåŠŸ" in msg['content']:
                 pass 

        with col_node:
            if msg['role'] == 'user' and msg['content'] in nodes_map:
                node = nodes_map[msg['content']]
                with st.expander(f"âœ¨ {node['care_point']}", expanded=False):
                    st.caption(f"MLS Logic: {node.get('logic_score', 0.5)}")
                    st.markdown(f"**Insight:** {node['insight']}")
                    st.markdown(f"**Structure:**\n{node['meaning_layer']}")
                    st.caption(f"Time: {node['created_at'][:16]}")

    if prompt := st.chat_input("è¾“å…¥..."):
        save_chat(st.session_state.username, "user", prompt)
        
        full_history = chat_history + [{'role':'user', 'content':prompt}]
        stream = get_normal_response(full_history)
        reply_text = st.write_stream(stream)
        save_chat(st.session_state.username, "assistant", reply_text)
        
        with st.spinner("âš¡ æ„ä¹‰åˆ¤åˆ« & é›·è¾¾æ‰«æ..."):
            analysis = analyze_meaning_background(prompt)
            if analysis.get("valid", False):
                vec = get_embedding(prompt)
                save_node(st.session_state.username, prompt, analysis, "æ—¥å¸¸", vec)
                
                # ğŸŒŸ æ›´æ–°ç”¨æˆ·çš„é›·è¾¾æ•°æ®
                if "radar_scores" in analysis:
                    update_radar_score(st.session_state.username, analysis["radar_scores"])
                
                match = find_resonance(vec, st.session_state.username)
                if match:
                    st.toast(f"ğŸ”” å‘ç°æ·±åº¦å…±é¸£ï¼", icon="âš¡")
        
        st.rerun()
